{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ambiguous_parsing.metrics.zeroshot_metrics import ZeroshotDatasetMetric\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR= Path(\"/brtx/602-nvme1/estengel/ambiguous_parsing/logs/1.0/\") \n",
    "fol_models_and_paths  = defaultdict(list)\n",
    "for model in [\"codegen-350M\", \"codegen-2B\", \"codegen-6B\", \"llama-13B\", \"vicuna-13B\", \"codegen-16B\"]:\n",
    "    for _type in [\"scope\", \"revscope\", \"bound\", \"conj\", \"pp\"]:\n",
    "        fol_models_and_paths[model].append((_type, f\"{model}_lamp_no_context_all_{_type}_fol_0_test_eval_constrained_bs_5_np_full\"))\n",
    "for model in ['gpt-3.5-turbo']:\n",
    "    for _type in [\"scope\", \"revscope\", \"bound\", \"conj\", \"pp\"]:\n",
    "        fol_models_and_paths[model].append((_type, f\"{model}_lamp_no_context_all_{_type}_fol_0_test_eval_unconstrained-api_bs_5_np_full\"))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics_by_k = {}\n",
    "for k in range(2, 6):\n",
    "        \n",
    "    big_metric_dict = ZeroshotDatasetMetric.from_bclamp_dirs(fol_models_and_paths, checkpoint_dir=CHECKPOINT_DIR, k=k, either=False, is_fol=True)\n",
    "    metrics_by_k[k] = big_metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "model & pp & scope & revscope & bound & conj \\\\\n",
      "\\midrule\n",
      "codegen-350M & 0.00 & 0.00 & 0.00 & 0.00 & 1.00 \\\\\n",
      "codegen-2B & 0.00 & 0.00 & 0.00 & 0.50 & 0.00 \\\\\n",
      "codegen-6B & 0.00 & 0.00 & 0.00 & 0.00 & 3.50 \\\\\n",
      "llama-13B & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n",
      "vicuna-13B & 0.00 & 0.00 & 0.00 & 4.00 & 9.50 \\\\\n",
      "codegen-16B & 0.00 & 0.00 & 0.00 & 3.50 & 15.00 \\\\\n",
      "gpt-3.5-turbo & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "zm_five = metrics_by_k[5]\n",
    "\n",
    "# turn into df for latex \n",
    "columns = ['pp', 'scope', 'revscope', 'bound', 'conj']\n",
    "df_data = []\n",
    "for model, metric in zm_five.items():\n",
    "    try:\n",
    "        df_data.append({\"model\": model, \"pp\": metric[\"pp\"], \"scope\": metric[\"scope\"], \"revscope\": metric[\"revscope\"], \"bound\": metric[\"bound\"], \"conj\": metric[\"conj\"]})\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "for col in columns:\n",
    "    df[col] *= 100\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# latex it \n",
    "print(df.to_latex(index=False, float_format=\"%.2f\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codegen-350M\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "4 = 0.80 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "5 = 1.00 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "8 = 1.60 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "6 = 1.20 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "6 = 1.20 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "10 = 2.00 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "5 = 1.00 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "codegen-2B\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "3 = 0.60 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "5 = 1.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "5 = 1.00 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "7 = 1.40 are missing a second output\n",
      "5 = 1.00 are missing a first output\n",
      "12 = 2.40 are missing a second output\n",
      "3 = 0.60 are missing a first output\n",
      "10 = 2.00 are missing a second output\n",
      "3 = 0.60 are missing a first output\n",
      "12 = 2.40 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "10 = 2.00 are missing a second output\n",
      "codegen-6B\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "4 = 0.80 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "3 = 0.60 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "9 = 1.80 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "6 = 1.20 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "11 = 2.20 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "11 = 2.20 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "10 = 2.00 are missing a second output\n",
      "codegen-16B\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "4 = 0.80 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "4 = 0.80 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "7 = 1.40 are missing a second output\n",
      "llama-13B\n",
      "482 = 96.40 are missing a first output\n",
      "499 = 99.80 are missing a second output\n",
      "483 = 96.60 are missing a first output\n",
      "499 = 99.80 are missing a second output\n",
      "481 = 96.20 are missing a first output\n",
      "499 = 99.80 are missing a second output\n",
      "475 = 95.00 are missing a first output\n",
      "499 = 99.80 are missing a second output\n",
      "472 = 94.40 are missing a first output\n",
      "497 = 99.40 are missing a second output\n",
      "Skipping 50-50 because pred and gold data are different lengths\n",
      "475 = 95.00 are missing a first output\n",
      "495 = 99.00 are missing a second output\n",
      "476 = 95.20 are missing a first output\n",
      "496 = 99.20 are missing a second output\n",
      "474 = 94.80 are missing a first output\n",
      "497 = 99.40 are missing a second output\n",
      "473 = 94.60 are missing a first output\n",
      "497 = 99.40 are missing a second output\n",
      "468 = 93.60 are missing a first output\n",
      "497 = 99.40 are missing a second output\n",
      "vicuna-13B\n",
      "0 = 0.00 are missing a first output\n",
      "7 = 1.40 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ambiguous_parsing.metrics.fewshot_metrics import FewshotDatasetMetric, FewshotInstanceMetric\n",
    "\n",
    "\n",
    "CHECKPOINT_DIR= Path(\"/brtx/602-nvme1/estengel/ambiguous_parsing/logs/1.0/\") \n",
    "\n",
    "big_metric_dict = {}\n",
    "for model in ['codegen-350M', 'codegen-2B', 'codegen-6B', 'codegen-16B', 'llama-13B', 'vicuna-13B']:\n",
    "    print(model)\n",
    "    fol_models_and_paths = [\n",
    "        (\"0-100\", f\"{model}_lamp_no_context_all_0-100-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"10-90\", f\"{model}_lamp_no_context_all_10-90-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"20-80\", f\"{model}_lamp_no_context_all_20-80-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"30-70\", f\"{model}_lamp_no_context_all_30-70-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"40-60\", f\"{model}_lamp_no_context_all_40-60-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"50-50\", f\"{model}_lamp_no_context_all_50-50-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"60-40\", f\"{model}_lamp_no_context_all_60-40-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"70-30\", f\"{model}_lamp_no_context_all_70-30-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"80-20\", f\"{model}_lamp_no_context_all_80-20-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"90-10\", f\"{model}_lamp_no_context_all_90-10-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"100-0\", f\"{model}_lamp_no_context_all_100-0-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "    ]\n",
    "    # all test files are same \n",
    "    fol_test_path = \"/brtx/602-nvme1/estengel/ambiguous_parsing/data/raw/50-50-5k-train-100-perc-ambig_fol/test.jsonl\"\n",
    "    fol_eval_path = \"/brtx/602-nvme1/estengel/ambiguous_parsing/data/raw/50-50-5k-train-100-perc-ambig_fol/test_eval.jsonl\"\n",
    "\n",
    "    metric_dict = FewshotDatasetMetric.from_bclamp_dir(fol_models_and_paths, \n",
    "                                                        fol_test_path, \n",
    "                                                        fol_eval_path,\n",
    "                                                        CHECKPOINT_DIR,\n",
    "                                                        is_fol=True)    \n",
    "\n",
    "    big_metric_dict[model] = metric_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codegen-350M\n",
      "codegen-2B\n",
      "codegen-6B\n",
      "codegen-16B\n",
      "llama-13B\n",
      "vicuna-13B\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ambiguous_parsing.metrics.fewshot_metrics import FewshotDatasetMetric, FewshotInstanceMetric\n",
    "\n",
    "\n",
    "CHECKPOINT_DIR= Path(\"/brtx/602-nvme1/estengel/ambiguous_parsing/model_outputs\") \n",
    "\n",
    "instance_metric_dict = {}\n",
    "for model in ['codegen-350M', 'codegen-2B', 'codegen-6B', 'codegen-16B', 'llama-13B', 'vicuna-13B' ]:\n",
    "    print(model)\n",
    "    fol_models_and_paths = [\n",
    "        (\"0-100\", f\"{model}/0-100-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"10-90\", f\"{model}/10-90-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"20-80\", f\"{model}/20-80-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"30-70\", f\"{model}/30-70-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"40-60\", f\"{model}/40-60-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"50-50\", f\"{model}/50-50-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"60-40\", f\"{model}/60-40-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"70-30\", f\"{model}/70-30-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"80-20\", f\"{model}/80-20-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"90-10\", f\"{model}/90-10-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "        (\"100-0\", f\"{model}/100-0-5k-train-100-perc-ambig_fol_fewshot/outputs/test_eval.logits\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # all test files are same \n",
    "    fol_test_path = \"/brtx/602-nvme1/estengel/ambiguous_parsing/data/raw/50-50-5k-train-100-perc-ambig_fol/test.jsonl\"\n",
    "    fol_eval_path = \"/brtx/602-nvme1/estengel/ambiguous_parsing/data/raw/50-50-5k-train-100-perc-ambig_fol/test_eval.jsonl\"\n",
    "\n",
    "    tuples = []\n",
    "    for s1s2, path in fol_models_and_paths:\n",
    "        s1 = int(s1s2.split(\"-\")[0])\n",
    "        tup = (fol_eval_path, CHECKPOINT_DIR/path, s1)\n",
    "        tuples.append(tup)\n",
    "\n",
    "    metric_dict = FewshotInstanceMetric.from_bclamp_paths(tuples)\n",
    "\n",
    "    instance_metric_dict[model] = metric_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_data = []\n",
    "\n",
    "for model in ['codegen-350M', 'codegen-2B', 'codegen-6B', 'codegen-16B', 'llama-13B', 'vicuna-13B']:\n",
    "    row_dict = {\"model\": model}\n",
    "    for _type in ['pp', 'scope', 'scope_reverse', 'bound', 'conj']:\n",
    "        instance_data = instance_metric_dict[model][_type]\n",
    "        dataset_data = big_metric_dict[model][_type]\n",
    "        row_dict[f\"{_type}_FDM\"] = dataset_data\n",
    "        row_dict[f\"{_type}_FIM\"] = instance_data\n",
    "    df_data.append(row_dict)\n",
    "df = pd.DataFrame(df_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "\\toprule\n",
      "model & pp_FDM & pp_FIM & scope_FDM & scope_FIM & scope_reverse_FDM & scope_reverse_FIM & bound_FDM & bound_FIM & conj_FDM & conj_FIM \\\\\n",
      "\\midrule\n",
      "codegen-350M & 0.76 & 0.08 & 0.19 & 0.05 & 0.36 & 0.06 & 0.62 & 0.16 & 0.60 & 0.06 \\\\\n",
      "codegen-2B & 0.51 & 0.09 & 0.19 & 0.03 & 0.18 & 0.03 & 0.48 & 0.10 & 0.39 & 0.05 \\\\\n",
      "codegen-6B & 0.45 & 0.08 & 0.21 & 0.05 & 0.16 & 0.06 & 0.43 & 0.10 & 0.41 & 0.06 \\\\\n",
      "codegen-16B & 0.35 & 0.08 & 0.20 & 0.03 & 0.21 & 0.03 & 0.38 & 0.10 & 0.27 & 0.06 \\\\\n",
      "llama-13B & 1.00 & 0.06 & 1.00 & 0.04 & 1.00 & 0.04 & 1.00 & 0.06 & 1.00 & 0.05 \\\\\n",
      "vicuna-13B & 0.50 & 0.08 & 0.17 & 0.05 & 0.20 & 0.06 & 0.26 & 0.07 & 0.35 & 0.09 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(index=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
