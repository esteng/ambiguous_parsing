{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ambiguous_parsing.metrics.zeroshot_metrics import ZeroshotDatasetMetric\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping codegen-6B conj because no files found\n",
      "Skipping codegen-16B conj because no files found\n",
      "Skipping codegen-6B conj because no files found\n",
      "Skipping codegen-16B conj because no files found\n",
      "Skipping codegen-6B conj because no files found\n",
      "Skipping codegen-16B conj because no files found\n",
      "Skipping codegen-6B conj because no files found\n",
      "Skipping codegen-16B conj because no files found\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR= Path(\"/brtx/602-nvme1/estengel/ambiguous_parsing/logs/1.0/\") \n",
    "fol_models_and_paths  = defaultdict(list)\n",
    "for model in [\"codegen-350M\", \"codegen-2B\", \"codegen-6B\", \"codegen-16B\"]:\n",
    "    for _type in [\"scope\", \"revscope\", \"bound\", \"conj\", \"pp\"]:\n",
    "        fol_models_and_paths[model].append((_type, f\"{model}_lamp_no_context_all_{_type}_fol_0_test_eval_constrained_bs_5_np_full\"))\n",
    "for model in ['gpt-3.5-turbo']:\n",
    "    for _type in [\"scope\", \"revscope\", \"bound\", \"conj\", \"pp\"]:\n",
    "        fol_models_and_paths[model].append((_type, f\"{model}_lamp_no_context_all_{_type}_fol_0_test_eval_unconstrained-api_bs_5_np_full\"))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics_by_k = {}\n",
    "for k in range(2, 6):\n",
    "        \n",
    "    big_metric_dict = ZeroshotDatasetMetric.from_bclamp_dirs(fol_models_and_paths, checkpoint_dir=CHECKPOINT_DIR, k=k, either=False, is_fol=True)\n",
    "    metrics_by_k[k] = big_metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "model & pp & scope & revscope & bound & conj \\\\\n",
      "\\midrule\n",
      "codegen-350M & 0.00 & 0.00 & 0.00 & 0.00 & 1.00 \\\\\n",
      "codegen-2B & 0.00 & 0.00 & 0.00 & 0.50 & 0.00 \\\\\n",
      "gpt-3.5-turbo & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "zm_five = metrics_by_k[5]\n",
    "\n",
    "# turn into df for latex \n",
    "columns = ['pp', 'scope', 'revscope', 'bound', 'conj']\n",
    "df_data = []\n",
    "for model, metric in zm_five.items():\n",
    "    try:\n",
    "        df_data.append({\"model\": model, \"pp\": metric[\"pp\"], \"scope\": metric[\"scope\"], \"revscope\": metric[\"revscope\"], \"bound\": metric[\"bound\"], \"conj\": metric[\"conj\"]})\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "for col in columns:\n",
    "    df[col] *= 100\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# latex it \n",
    "print(df.to_latex(index=False, float_format=\"%.2f\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codegen-350M\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "4 = 0.80 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "5 = 1.00 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "8 = 1.60 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "6 = 1.20 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "6 = 1.20 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "10 = 2.00 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "5 = 1.00 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "codegen-2B\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "3 = 0.60 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "5 = 1.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "5 = 1.00 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "7 = 1.40 are missing a second output\n",
      "5 = 1.00 are missing a first output\n",
      "12 = 2.40 are missing a second output\n",
      "3 = 0.60 are missing a first output\n",
      "10 = 2.00 are missing a second output\n",
      "3 = 0.60 are missing a first output\n",
      "12 = 2.40 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "10 = 2.00 are missing a second output\n",
      "codegen-6B\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "4 = 0.80 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "3 = 0.60 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "9 = 1.80 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "6 = 1.20 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "11 = 2.20 are missing a second output\n",
      "2 = 0.40 are missing a first output\n",
      "11 = 2.20 are missing a second output\n",
      "Skipping 100-0 because pred and gold data are different lengths\n",
      "codegen-16B\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "0 = 0.00 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "1 = 0.20 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "4 = 0.80 are missing a second output\n",
      "0 = 0.00 are missing a first output\n",
      "2 = 0.40 are missing a second output\n",
      "1 = 0.20 are missing a first output\n",
      "4 = 0.80 are missing a second output\n",
      "Skipping 100-0 because no jsonl file found\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ambiguous_parsing.metrics.fewshot_metrics import FewshotDatasetMetric, FewshotInstanceMetric\n",
    "\n",
    "\n",
    "CHECKPOINT_DIR= Path(\"/brtx/602-nvme1/estengel/ambiguous_parsing/logs/1.0/\") \n",
    "\n",
    "big_metric_dict = {}\n",
    "for model in ['codegen-350M', 'codegen-2B', 'codegen-6B', 'codegen-16B']:\n",
    "    print(model)\n",
    "    fol_models_and_paths = [\n",
    "        (\"0-100\", f\"{model}_lamp_no_context_all_0-100-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"10-90\", f\"{model}_lamp_no_context_all_10-90-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"20-80\", f\"{model}_lamp_no_context_all_20-80-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"30-70\", f\"{model}_lamp_no_context_all_30-70-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"40-60\", f\"{model}_lamp_no_context_all_40-60-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"50-50\", f\"{model}_lamp_no_context_all_50-50-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"60-40\", f\"{model}_lamp_no_context_all_60-40-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"70-30\", f\"{model}_lamp_no_context_all_70-30-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"80-20\", f\"{model}_lamp_no_context_all_80-20-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"90-10\", f\"{model}_lamp_no_context_all_90-10-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "        (\"100-0\", f\"{model}_lamp_no_context_all_100-0-5k-train-100-perc-ambig_fol_fewshot_2_test_eval_constrained_bs_5_np_10/\"),\n",
    "    ]\n",
    "    # all test files are same \n",
    "    fol_test_path = \"/brtx/602-nvme1/estengel/ambiguous_parsing/data/raw/50-50-5k-train-100-perc-ambig_fol/test.jsonl\"\n",
    "    fol_eval_path = \"/brtx/602-nvme1/estengel/ambiguous_parsing/data/raw/50-50-5k-train-100-perc-ambig_fol/test_eval.jsonl\"\n",
    "\n",
    "    metric_dict = FewshotDatasetMetric.from_bclamp_dir(fol_models_and_paths, \n",
    "                                                        fol_test_path, \n",
    "                                                        fol_eval_path,\n",
    "                                                        CHECKPOINT_DIR,\n",
    "                                                        is_fol=True)    \n",
    "    big_metric_dict[model] = metric_dict\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
